{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "43acf223-9c88-4b10-bd83-39e96164929e"
    }
   },
   "source": [
    "Load packages and use tensorflow as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "4701a722-88f0-4de7-9d04-344a467a7a97"
    }
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "# import system level packages\n",
    "import sys\n",
    "#!{sys.executable} -m pip install numpy\n",
    "#!{sys.executable} -m pip install requests\n",
    "#import requests\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras import utils\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "#from .tqdm_callback import TQDMNotebookCallback\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "978f4a8a-2573-4225-96e9-b6d856afb770"
    }
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "#test tensorflow, remember to change the kernel\n",
    "#using kernel that supports GPU computing\n",
    "#simple test to confirm tensorflow is actually working\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(\"10 + 32 = \", sess.run(a + b))\n",
    "\n",
    "#manually set the random seed to define a replication\n",
    "r_seed = 87\n",
    "\n",
    "#manually set the number for cross validation\n",
    "num_cv = 5\n",
    "\n",
    "print(\"current random seed is: \", r_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bf45f99d-126e-4d56-a407-1536356a5b91"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "#check the system information, check if cuda and gpu computing for tensorflow is installed properly\n",
    "print(\"whether tensorflow is built with cuda: \", tf.test.is_built_with_cuda())\n",
    "print(\"whether gpu computing is available for tensorflow: \", tf.test.is_gpu_available())\n",
    "print(\"using keras version: \", keras.__version__)\n",
    "print(\"using tensorflow version: \", tf.__version__)\n",
    "print(\"\\n\")\n",
    "print(\"Device details:\\n\", device_lib.list_local_devices())\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b605f27a-f331-41b4-a568-2a852ae6a08c"
    }
   },
   "source": [
    "Traditional machine learning methods on compressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "2e63e93e-d5bb-4e7a-8daf-bbd570b03ca1"
    }
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Reading files/documents\n",
    "#vae file\n",
    "compress_path = 'counts_data/vae_compressed_wLabels/encoded_COAD_rnaseq_vae_binaryLabels(perSp,a1.0,unlabel,0.2_var,2LF12k,z350,minma).txt'\n",
    "\n",
    "#vae with grade file\n",
    "#compress_path = 'counts_data/vae_compressed_with_grade/TCGA_4cancers_(BLCA_perSP_minmax_3labels_6LF6k_z200)_with_grade.txt'\n",
    "# vae with stage file\n",
    "#compress_path = 'counts_data/vae_compressed_with_stage/TCGA_4cancers_(PAAD_perSP_minmax_3labels_6LF6k_z50)_with_stage.txt'\n",
    "\n",
    "\n",
    "#open(path).readline()\n",
    "#gene expression RNAseq, Batch effects normalized mRNA data\n",
    "\n",
    "og_data = pd.read_csv(compress_path, sep = \"\\t\", index_col = 0)\n",
    "og_data = og_data.dropna(axis='columns')\n",
    "#ExprAlldata.columns = [\"Gene\", \"Counts\"]\n",
    "print(\"dimension of the input data: \", og_data.shape)\n",
    "og_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0350a6a2-bb4e-430c-b348-b36c7381b94f"
    }
   },
   "source": [
    "Number of cases in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bef8c083-fce9-40a2-b53b-fb08c2979c44"
    }
   },
   "outputs": [],
   "source": [
    "df_count = og_data.groupby('response_group')['Ensembl_ID'].nunique()\n",
    "print(df_count)\n",
    "#df_count.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "#store the raw data, and use ensembl id as index\n",
    "#\n",
    "df_raw = og_data.iloc[:, 0:]\n",
    "df_raw = df_raw.set_index('Ensembl_ID')\n",
    "\n",
    "#notice the last column is the response_group\n",
    "#df_raw.shape\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################!#################################\n",
    "#here begins full data\n",
    "################################\n",
    "#full data, 4 labels analysis\n",
    "#Complete Response    21\n",
    "#Clinical Progressive Disease    10\n",
    "#Radiographic Progressive Disease     7\n",
    "#Stable Disease     7\n",
    "\n",
    "#features\n",
    "df_raw_coln = len(df_raw.columns)\n",
    "X = df_raw.iloc[:,0:(df_raw_coln-1)]\n",
    "X = X.values\n",
    "\n",
    "#label/target\n",
    "y = df_raw.loc[:, 'response_group']\n",
    "y = y.values\n",
    "\n",
    "#!!!!!!!\n",
    "#check to confirm the last column is not response group, only y contains response group information\n",
    "col = X.shape[1]\n",
    "print(X[:,(col-1)])\n",
    "\n",
    "#df_cancer.head(10)\n",
    "#df_normal.head(10)\n",
    "\n",
    "class_names = np.unique(y)\n",
    "print(\"unique labels from y: \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c91bff03-2c49-4189-95ee-f8bdb5fb9660"
    }
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "#importing necessary libraries for scikit-learn\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "#from sklearn.grid_search import GridSearchCV   #!!!the grid search package that has issue, dont use it\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "#plot confusion matrix\n",
    "#inputs: cm, confusion matrix from cross_val_predict\n",
    "#        normalize, whether to use normalize for each sections \n",
    "#        title, input the title name for the figure\n",
    "#        cmap, color map using blue as default\n",
    "#output: a confusion matrix plot with true label as y axis, and predicted label as x axis\n",
    "#########################################################################################\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#plot area under curve graph\n",
    "#input: actual, true labels/target without one hot encoding\n",
    "#       probs, predicted probabilities\n",
    "#       n_classes, number of unique classes in target\n",
    "#       title, input the title name for the figure\n",
    "#output: a roc curve plot for multi class task\n",
    "###############################################################\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_multiclass_roc_auc(actual, probs, n_classes, title = 'multi-class roc'):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(actual)\n",
    "    actual = lb.transform(actual)\n",
    "    y_prob = probs\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(actual[:, i], y_prob[:, i])\n",
    "        #please notice the difference between auc() and roc_auc_score()\n",
    "        #also auc() only works on monotonic increasing or monotonic\n",
    "        #decreasing input x\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        colors = cycle(['blue', 'red', 'green', 'orange'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color,\n",
    "        label='ROC curve of class {0} (area = {1:0.10f})'\n",
    "            ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for multi-class data using '+title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #commented thus being able to use fig save function\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#Random search CV method\n",
    "#and\n",
    "#Multi class roc_auc score method\n",
    "########################################################\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "###########################################################################################\n",
    "#Multi class roc_auc score method\n",
    "#input: y_test, true labels from test fold\n",
    "#       y_prob, predicted probability on test fold\n",
    "#       average, string, [None, ‘micro’, ‘macro’ (default), ‘samples’, ‘weighted’]\n",
    "#                'macro': Calculate metrics for each label, and find their unweighted mean. \n",
    "#                This does not take label imbalance into account.\n",
    "#                'weighted': Calculate metrics for each label, and find their average, \n",
    "#                weighted by support (the number of true instances for each label).\n",
    "#output: auroc value for each class\n",
    "#multiclass_score, an implemented scoring method for multi class task\n",
    "#!!!\n",
    "#Notice that by default,needs_proba : boolean, default=False\n",
    "#thus the multiclass_score will try to use the predicted label instead of predicted probability to calculate roc\n",
    "#which is not correct, and will causing the tuning process to not find the best parameters\n",
    "##############################################################################################\n",
    "def multiclass_roc_auc_score(y_test, y_prob, average=\"weighted\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    #y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_prob, average=average)\n",
    "\n",
    "#!!!\n",
    "#Notice that by default,needs_proba : boolean, default=False\n",
    "#thus the multiclass_score will try to use the predicted label instead of predicted probability to calculate roc\n",
    "#which is not correct, and will causing the tuning process to not find the best parameters\n",
    "multiclass_score = make_scorer(multiclass_roc_auc_score, needs_proba = True)\n",
    "\n",
    "###############################################################################################\n",
    "#Binary class roc auc score method\n",
    "#input: y_true, true labels from test fold\n",
    "#       y_score, predicted probability on test fold\n",
    "#       average, string, [None, ‘micro’, ‘macro’ (default), ‘samples’, ‘weighted’]\n",
    "#                'macro': Calculate metrics for each label, and find their unweighted mean. \n",
    "#                This does not take label imbalance into account.\n",
    "#                'weighted': Calculate metrics for each label, and find their average, \n",
    "#                weighted by support (the number of true instances for each label).\n",
    "#output: auroc value for each class\n",
    "#############################################################################################\n",
    "def binary_class_roc_auc_score(y_true, y_score, average=\"weighted\"):\n",
    "\n",
    "    return roc_auc_score(y_true, y_score, average=average)\n",
    "\n",
    "binaryclass_score = make_scorer(binary_class_roc_auc_score, needs_threshold = True)\n",
    "\n",
    "###################################################################################\n",
    "#Random search CV method\n",
    "#input: est, input estimator/classifier\n",
    "#       p_distr, the grid of parameters to search on\n",
    "#       nbr_iter, numbers of iteration on random search\n",
    "#       X, feature, y, true labels\n",
    "#output: ht_estimator, best estimator based on mean value of all folds\n",
    "#        ht_params, best parameters\n",
    "#\n",
    "################################################################################################\n",
    "def hypertuning_rscv(est, p_distr, nbr_iter,X,y):\n",
    "    #seed = 42\n",
    "    cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "    rdmsearch = RandomizedSearchCV(est, param_distributions=p_distr, scoring=multiclass_score,\n",
    "                                  n_jobs=-1, n_iter=nbr_iter, cv=cv, return_train_score = True, verbose =10)\n",
    "    #CV = Cross-Validation ( here using Stratified KFold CV) #,random_state = seed\n",
    "    start = time()\n",
    "    rdmsearch.fit(X,y)\n",
    "    print('hyper-tuning time : %d seconds' % (time()-start))\n",
    "    start = 0\n",
    "   # ht_train_mean = rdmsearch.cv_results_['mean_train_score']\n",
    "   # ht_train_std = rdmsearch.cv_results_['std_train_score']\n",
    "   # ht_test_mean_sp0 = rdmsearch.cv_results_['split0_test_score']\n",
    "   # ht_test_mean_sp1 = rdmsearch.cv_results_['split1_test_score']\n",
    "   # ht_test_mean_sp2 = rdmsearch.cv_results_['split2_test_score']\n",
    "    #ht_train_mean_sp3 = rdmsearch.cv_results_['split3_train_score']\n",
    "    #ht_train_mean_sp4 = rdmsearch.cv_results_['split4_train_score']\n",
    "    #ht_best_loc = np.where(rdmsearch.cv_results_['rank_test_score'] == 1)\n",
    "    \n",
    "    ht_cv_results = rdmsearch.cv_results_\n",
    "    ht_estimator = rdmsearch.best_estimator_\n",
    "    ht_params = rdmsearch.best_params_\n",
    "    #ht_score = rdmsearch.best_score_\n",
    "    \n",
    "    return ht_estimator, ht_params, ht_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1db5a3ed-8143-492e-8636-c7d5170d987e"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#just backup pipeline to train a default knn estimator\n",
    "#test to confirm whether is imbalanced number in folds changes result\n",
    "###############################################################################\n",
    "#KNN\n",
    "# dividing X, y into train and test data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 42)\n",
    " \n",
    "# training a KNN classifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#knn = KNeighborsClassifier(n_neighbors = 6, p = 3, weights = \"distance\", algorithm = \"ball_tree\", \n",
    "#                          leaf_size = 18).fit(X_train, y_train)\n",
    "\n",
    "#accuracy on X_test\n",
    "#accuracy = knn.score(X_test, y_test)\n",
    "#print (accuracy)\n",
    "\n",
    "# return predict probability\n",
    "#knn_prob = knn.predict_proba(X_test)\n",
    "#print(knn_prob)\n",
    "\n",
    "# calculate the auroc by directly using the multiclass_roc_auc_score scorer\n",
    "#knn_multiclass_auroc = multiclass_roc_auc_score(y_test, knn_prob, average=\"macro\")\n",
    "#print(knn_multiclass_auroc)\n",
    "\n",
    "# calculate the individual auroc and then calculate the mean by plotting on figure\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize = (10, 8))\n",
    "#plot_multiclass_roc_auc(y_test, knn_prob, n_classes = 4, title = \"test, knn\")\n",
    "#plt.savefig('test.png')\n",
    "\n",
    "#print((0.53704+0.69318+0.72222+1)/4)\n",
    "# creating a confusion matrix\n",
    "#knn_predictions = knn.predict(X_test) \n",
    "#cm = confusion_matrix(y_test, knn_predictions)\n",
    "\n",
    "# training a KNN classifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "#knn_scores = cross_val_score(knn, X, y, cv = 5)\n",
    "#print(knn)\n",
    "#print(\"Accuracy: %0.5f (+/- %0.4f)\" % (knn_scores.mean(), stats.sem(knn_scores) * 2))\n",
    "\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#y_knn_pred = cross_val_predict(knn, X, y, cv = 3)\n",
    "#knn_conf_mat = confusion_matrix(y,y_knn_pred)\n",
    "#print(knn_conf_mat)\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import itertools\n",
    "\n",
    "#plt.figure(figsize = (14, 14))\n",
    "#plot_confusion_matrix(knn_conf_mat, classes=class_names,\n",
    "#                      title='Confusion matrix knn, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#Grid search Tune LNN\n",
    "#default, without bagging and Ensemble\n",
    "###################################################\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#param_test1 = {\n",
    "#            'n_neighbors':[i for i in range(1,20)],\n",
    "#            'weights':['uniform', 'distance'],\n",
    "#            'algorithm':['ball_tree', 'kd_tree','brute','auto'],\n",
    "#            'leaf_size':[i for i in range(1,20)],\n",
    "#            'p':[i for i in range(1,3)]\n",
    "#}\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "\n",
    "#gsearch1 = GridSearchCV(estimator = KNeighborsClassifier(), \n",
    "#param_grid = param_test1, scoring=multiclass_score,n_jobs=-1,iid=False, cv=cv, return_train_score=True)\n",
    "#gsearch1.fit(X,y)\n",
    "#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does have overfitting issue\n",
    "#print(gsearch1.cv_results_[\"split1_train_score\"])\n",
    "#print(gsearch1.cv_results_[\"split1_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#Tuning KNN with Grid search\n",
    "#output: best estimator and best parameters\n",
    "#default, with bagging and Ensemble\n",
    "###################################################\n",
    "#param_test1 = {\n",
    "#            'n_neighbors':[i for i in range(1,20)],\n",
    "#            'weights':['uniform', 'distance'],\n",
    "#            'algorithm':['ball_tree', 'kd_tree','brute','auto'],\n",
    "#            'leaf_size':[i for i in range(1,20)],\n",
    "#            'p':[i for i in range(1,4)]\n",
    "#}\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "\n",
    "#gsearch1 = GridSearchCV(estimator = KNeighborsClassifier(), \n",
    "#param_grid = param_test1, scoring=multiclass_score,n_jobs=-1,iid=False, cv=cv, return_train_score=True, verbose = 10)\n",
    "#gsearch1.fit(X,y)\n",
    "#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does have overfitting issue\n",
    "#print(gsearch1.cv_results_[\"split1_train_score\"])\n",
    "#print(gsearch1.cv_results_[\"split1_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "#Tuning KNN with randomsearch\n",
    "#output: best estimator and best parameters\n",
    "#!!!\n",
    "##Notice there is issue with the best_score_ output from the randomSearchCV, dont use it\n",
    "#############################################################################################\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#est = KNeighborsClassifier()\n",
    "\n",
    "#knn_p_dist={'n_neighbors':[i for i in range(1,20)],\n",
    "#            'weights':['uniform', 'distance'],\n",
    "#            'algorithm':['ball_tree', 'kd_tree','brute','auto'],\n",
    "#            'leaf_size':[i for i in range(1,20)],\n",
    "#            'p':[i for i in range(1,5)]\n",
    "#           }\n",
    "\n",
    "#knn_estimator, knn_parameters, knn_cv_results = hypertuning_rscv(est, knn_p_dist, 800, X, y)\n",
    "#print(knn_parameters)\n",
    "\n",
    "#!!!\n",
    "#Notice there is issue with the best_score_ output from the randomSearchCV\n",
    "#print('Hyper-tuned model score :')\n",
    "#print(knn_ht_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(knn_cv_results[\"split1_train_score\"])\n",
    "#print(knn_cv_results[\"split1_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#training a KNN classifier use best estimator found by random search\n",
    "######################################################################\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#knn = KNeighborsClassifier(n_neighbors = 6, weights = 'distance', leaf_size =1, algorithm = 'ball_tree', \n",
    "#                           p=2)\n",
    "\n",
    "# if using the randomSearch method\n",
    "#knn = knn_estimator\n",
    "\n",
    "# if using GridSearch method\n",
    "#knn = gsearch1.best_estimator_\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "\n",
    "##!!!!\n",
    "#notice that mean of auroc of each fold is different from the auroc calculated by all the predicted probability\n",
    "#knn_scores = cross_val_score(knn, X, y, cv = cv, scoring=multiclass_score)\n",
    "#y_knn_prob = cross_val_predict(knn, X, y, cv = cv, method = 'predict_proba')\n",
    "\n",
    "# calculate the auroc by directly using the multiclass_roc_auc_score scorer\n",
    "#knn_multiclass_auroc = multiclass_roc_auc_score(y, y_knn_prob, average=\"weighted\")\n",
    "\n",
    "#print(knn)\n",
    "#print(\"Auroc across all folds: %0.5f\" % (knn_multiclass_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#print out confusion matrix\n",
    "###############################################\n",
    "\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "#y_knn_pred = cross_val_predict(knn, X, y, cv = cv)\n",
    "#knn_conf_mat = confusion_matrix(y,y_knn_pred)\n",
    "\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#print(roc_auc_score(y, y_knn_pred))\n",
    "\n",
    "#print(knn_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#print out multiclass roc auc figure\n",
    "###############################################\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "#y_knn_prob = cross_val_predict(knn, X, y, cv = cv, method = 'predict_proba')\n",
    "\n",
    "#print(y_knn_prob)\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize = (10, 8))\n",
    "#plot_multiclass_roc_auc(y, y_knn_prob, n_classes = 3, title = \"knn, SARC_high_var_0.2, 3 layers\")\n",
    "#plt.savefig('(0606)3class_roc_auc_knn(3layersAll500_0.1test)(SARC_high_var_0.2).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#Generate confusion matrix figure and save those figures\n",
    "#Notice remember to change file name based on the input dataset\n",
    "###################################################################\n",
    "#import matplotlib.pyplot as plt\n",
    "#import itertools\n",
    "#from matplotlib.pyplot import legend\n",
    "\n",
    "#labels = ['Complete Response', 'Clinical Progressive Disease', 'Radiographic Progressive Disease', 'Stable Disease']\n",
    "\n",
    "#plt.figure(figsize = (20, 15))\n",
    "#legend(labels)\n",
    "#plot_confusion_matrix(knn_conf_mat, classes=labels,\n",
    "#                      title='Confusion matrix knn, without normalization')\n",
    "#plt.savefig('(0414)Confusion_matrix_knn(SARC0.1)(without_normalization).png')\n",
    "\n",
    "\n",
    "#plt.figure(figsize = (20, 15))\n",
    "#legend(labels)\n",
    "#plot_confusion_matrix(knn_conf_mat, classes=labels, normalize = True,\n",
    "#                      title='Normalized Confusion matrix knn')\n",
    "#plt.savefig('(0414)Confusion_matrix_knn(SARC0.1)(normalized).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3469af12-879c-4e7b-8e6b-54b56870127d"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#just backup pipeline to train a defaultlinear SVM classifier\n",
    "#test to confirm whether is imbalanced number in folds changes result\n",
    "###############################################################################\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "#svm_predictions = svm_model_linear.predict(X_test)\n",
    " \n",
    "# model accuracy for X_test  \n",
    "#accuracy = svm_model_linear.score(X_test, y_test)\n",
    "#print(accuracy)\n",
    "\n",
    "# creating a confusion matrix\n",
    "#cm = confusion_matrix(y_test, svm_predictions)\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#svm_model_linear = SVC(kernel = 'linear', C = 1)\n",
    "#svm_scores = cross_val_score(svm_model_linear, X, y, cv = 5)\n",
    "#print(svm_model_linear)\n",
    "#print(\"Accuracy: %0.4f (+/- %0.4f)\" % (svm_scores.mean(), stats.sem(svm_scores) * 2))\n",
    "\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#y_svm_pred = cross_val_predict(svm_model_linear, X, y, cv = 10)\n",
    "#svm_conf_mat = confusion_matrix(y,y_svm_pred)\n",
    "#print(svm_conf_mat)\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import itertools\n",
    "\n",
    "#plt.figure(figsize = (14, 14))\n",
    "#plot_confusion_matrix(svm_conf_mat, classes=class_names,\n",
    "#                      title='Confusion matrix svm, without normalization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#Tuning SVM with Grid search\n",
    "#output: best estimator and best parameters\n",
    "#default, with bagging and Ensemble\n",
    "###################################################\n",
    "#param_test2 = {\n",
    "#            'kernel':['linear','poly','rbf','sigmoid'],\n",
    "#            'C':[i for i in range(5, 50)],\n",
    "#            'gamma':['auto'],\n",
    "#            'degree':[i for i in range(1,20)],\n",
    "#            'probability':[True],\n",
    "#            #'max_iter':[2000],\n",
    "#            'random_state':[42]\n",
    "#}\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "\n",
    "#gsearch2 = GridSearchCV(estimator = SVC(), \n",
    "#param_grid = param_test2, scoring=multiclass_score,n_jobs=-1,iid=False, cv=cv, return_train_score=True, verbose =10)\n",
    "#gsearch2.fit(X,y)\n",
    "#gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice that SVM need the input X to be scaled to [-1, 1] range\n",
    "#therefore using Standarization to transform X first\n",
    "# Standardize\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#scaler.fit((X))\n",
    "#X_std = scaler.transform(X)\n",
    "#print(X_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#Tuning SVM with randomsearch\n",
    "########################################\n",
    "#from sklearn.svm import SVC\n",
    "#est = SVC()\n",
    "#from scipy.stats import norm\n",
    "#svc_p_dist={'kernel':['linear','poly','rbf','sigmoid'],\n",
    "#            'C':[i/10 for i in range (1,1000)],\n",
    "#            'gamma':['auto'],\n",
    "#            'degree':[i for i in range(1,50)],\n",
    "#            'probability':[True],\n",
    "#            #'max_iter':[2000],\n",
    "#            'random_state':[42]}\n",
    "\n",
    "#svc_estimator, svc_parameters, svc_cv_results = hypertuning_rscv(est, svc_p_dist, 700, X_std, y)\n",
    "\n",
    "#print(svc_parameters)\n",
    "\n",
    "#print('Hyper-tuned model score :')\n",
    "#print(svc_ht_score*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(svc_cv_results[\"split1_train_score\"])\n",
    "#print(svc_cv_results[\"split1_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.svm import SVC\n",
    "#svm_model_linear = SVC(kernel = 'linear', C = 0.4861735698828815, probability = True)\n",
    "\n",
    "# if using the randomSearch method\n",
    "#svm_model_linear = svc_estimator\n",
    "\n",
    "# if using GridSearch method\n",
    "#svm_model_linear = gsearch2.best_estimator_\n",
    "\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "\n",
    "##!!!!\n",
    "#notice that mean of auroc of each fold is different from the auroc calculated by all the predicted probability\n",
    "#svm_scores = cross_val_score(svm_model_linear, X, y, cv = cv, scoring=multiclass_score)\n",
    "#y_svm_prob = cross_val_predict(svm_model_linear, X, y, cv = cv, method = 'predict_proba')\n",
    "\n",
    "# calculate the auroc by directly using the multiclass_roc_auc_score scorer\n",
    "#svm_multiclass_auroc = multiclass_roc_auc_score(y, y_svm_prob, average=\"weighted\")\n",
    "\n",
    "#print(svm_model_linear)\n",
    "#print(\"Auroc across all folds: %0.5f\" % (svm_multiclass_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "#y_svm_pred = cross_val_predict(svm_model_linear, X, y, cv = cv)\n",
    "#svm_conf_mat = confusion_matrix(y,y_svm_pred)\n",
    "\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#print(roc_auc_score(y, y_svm_pred))\n",
    "\n",
    "#print(svm_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0.46627+0.52571+0.46992+0.93233)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#print out multiclass roc auc figure\n",
    "############################################\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "#y_svm_prob = cross_val_predict(svm_model_linear, X, y, cv = cv, method = 'predict_proba')\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize = (10, 8))\n",
    "#plot_multiclass_roc_auc(y, y_svm_prob, n_classes = 3, title = \"svm, SARC_high_var_0.2, 3 layers\")\n",
    "#plt.savefig('(0606)3class_roc_auc_svm(3layersAll500_0.1test)(SARC_high_var_0.2).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#Generate confusion matrix figure and save those figures\n",
    "#Notice remember to change file name based on the input dataset\n",
    "###################################################################\n",
    "#import matplotlib.pyplot as plt\n",
    "#import itertools\n",
    "#from matplotlib.pyplot import legend\n",
    "\n",
    "#labels = ['Complete Response', 'Clinical Progressive Disease', 'Radiographic Progressive Disease', 'Stable Disease']\n",
    "\n",
    "#plt.figure(figsize = (20, 15))\n",
    "#legend(labels)\n",
    "#plot_confusion_matrix(svm_conf_mat, classes=labels,\n",
    "#                      title='Confusion matrix svm, without normalization')\n",
    "#plt.savefig('(0414)Confusion_matrix_svm(SARC0.1)(without_normalization).png')\n",
    "\n",
    "\n",
    "#plt.figure(figsize = (20, 15))\n",
    "#legend(labels)\n",
    "#plot_confusion_matrix(svm_conf_mat, classes=labels, normalize = True,\n",
    "#                      title='Normalized Confusion matrix svm')\n",
    "#plt.savefig('(0414)Confusion_matrix_svm(SARC0.1)(normalized).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "be92a3df-606c-4a60-8ead-91bf99aac018"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#just backup pipeline to train a XGBoost model\n",
    "#test to confirm whether is imbalanced number in folds changes result\n",
    "###############################################################################\n",
    "#xgb = XGBClassifier(\n",
    "#                    learning_rate =0.1,\n",
    "#                    n_estimators=1000,\n",
    "#                    max_depth=5,\n",
    "#                     min_child_weight=1,\n",
    "#                     gamma=0,\n",
    "#                     subsample=0.8,\n",
    "#                     colsample_bytree=0.8,\n",
    "#                     objective= 'binary:logistic',\n",
    "#                     scale_pos_weight=1,\n",
    "#                    seed=42)\n",
    "\n",
    "#xgb_scores = cross_val_score(xgb, X, y, cv = 3)\n",
    "#print(xgb)\n",
    "#print(\"Accuracy: %0.5f (+/- %0.4f)\" % (xgb_scores.mean(), stats.sem(xgb_scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#Tuning XGboost with Grid search\n",
    "#output: best estimator and best parameters\n",
    "#default\n",
    "###################################################\n",
    "#param_test3 = {\n",
    "#            'learning_rate':[0.4, 0.5, 0.6],\n",
    "#            'n_estimators':[i for i in range(12,20)],\n",
    "            #'n_estimators':[i for i in range(1,10)],\n",
    "#            'max_depth':[i for i in range(12,20)],\n",
    "#             'min_child_weight':[i for i in range(0,10)],\n",
    "#             'booster':['gbtree','gblinear','dart'],\n",
    "#             'subsample':[i/100.0 for i in range(70,90)],\n",
    "#             'colsample_bytree':[i/100.0 for i in range(40,65)],\n",
    "#             'reg_alpha':[i for i in range(0,5)],\n",
    "#             'reg_lambda':[i for i in range(100,120)],\n",
    "#             'silent':[True],\n",
    "#             'random_state':[42]\n",
    "#}\n",
    "#cv = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "\n",
    "#gsearch3 = GridSearchCV(estimator = XGBClassifier(), \n",
    "#param_grid = param_test3, scoring=multiclass_score,n_jobs=-1,iid=False, cv=cv, return_train_score=True,verbose=10)\n",
    "#gsearch3.fit(X,y)\n",
    "#gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#Grid search Tune learning rate, n_estimators, and booster\n",
    "#default is max_depth = 5, min_child_weight = 1\n",
    "###################################################\n",
    "param_test3 = {\n",
    " 'learning_rate':[0.05, 0.1, 0.2, 0.4, 0.6, 0.8],\n",
    " 'n_estimators':[i for i in range(1,40)],\n",
    " 'booster':['gbtree'],\n",
    " #'booster':['gbtree','gblinear','dart'],\n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(), \n",
    " param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#output grid scores, and save to a file\n",
    "#\n",
    "#xgb_grid_scores = pd.DataFrame(gsearch1.grid_scores_)\n",
    "#xgb_grid_file = os.path.join(\"Tuning_insights\", \"xgb_grid_socres(lr&n_estimators).tsv\")\n",
    "#xgb_grid_scores.to_csv(xgb_grid_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Grid search Tune max_depth and min_child_weight\n",
    "#default\n",
    "#################################\n",
    "param_test3 = {\n",
    " 'max_depth':[i for i in range(1,10)],\n",
    " 'min_child_weight':[i for i in range(0,10)],\n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.4, n_estimators=36, booster = 'gbtree'), \n",
    " param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Grid search Tune subsample and colsample\n",
    "#\n",
    "#################################\n",
    "param_test3 = {\n",
    "             'subsample':[i/100.0 for i in range(10,110,10)],\n",
    "             'colsample_bytree':[i/100.0 for i in range(10,110,10)],\n",
    "             \n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.4, n_estimators=36, booster = 'gbtree',\n",
    "                                                 max_depth =1, min_child_weight=9), \n",
    "  param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Grid search Tune subsample and colsample\n",
    "#\n",
    "#################################\n",
    "param_test3 = {\n",
    "             'reg_alpha':[i for i in range(0,3)],\n",
    "             'reg_lambda':[i for i in range(1,100)],\n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.4, n_estimators=36, booster = 'gbtree',\n",
    "                                                 max_depth =1, min_child_weight=9, subsample = 0.8,\n",
    "                                                 colsample_bytree = 0.7), \n",
    "  param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Use random search to train a XGBoost model\n",
    "# with bagging\n",
    "###################################################\n",
    "#est = XGBClassifier()\n",
    "#param_test_rand = {\n",
    "#            'learning_rate':[0.4,0.5,0.7],\n",
    "#            'n_estimators':[i for i in range(12,20)],\n",
    "#            #'n_estimators':[i for i in range(1,10)],\n",
    "#            'max_depth':[i for i in range(12,20)],\n",
    "#            'min_child_weight':[i for i in range(0,5)],\n",
    "#             'booster':['gbtree','gblinear','dart'],\n",
    "#             'subsample':[i/100.0 for i in range(70,90)],\n",
    "#             'colsample_bytree':[i/100.0 for i in range(40,60)],\n",
    "#             'reg_alpha':[i for i in range(0,5)],\n",
    "#             'reg_lambda':[i for i in range(100,120)],\n",
    "#             'silent':[True],\n",
    "#             'random_state':[42]   \n",
    "\n",
    " #'learning_rate':[0.1, 0.01, 0.001, 0.0001],\n",
    " #'n_estimators':[i for i in range(1,1000,10)],\n",
    " #'n_estimators':[i for i in range(1,10)],\n",
    " #'max_depth':[i for i in range(1,30)],\n",
    " #'min_child_weight':[i for i in range(0,10)],\n",
    " #'booster':['gbtree','gblinear','dart'],\n",
    " #'subsample':[i/100.0 for i in range(1,100,1)],\n",
    " #'colsample_bytree':[i/100.0 for i in range(1,100,1)],\n",
    " #'reg_alpha':[i for i in range(0,10)],\n",
    " #'reg_lambda':[i for i in range(0,100)],\n",
    " #'silent':[True],\n",
    " #'random_state':[42]\n",
    "#}\n",
    "\n",
    "#gb_estimator, gb_parameters, gb_cv_results = hypertuning_rscv(est, param_test_rand, 6000, X, y)\n",
    "\n",
    "#print(gb_parameters)\n",
    "\n",
    "#print('Hyper-tuned model score :')\n",
    "#print(gb_ht_score*100)\n",
    "\n",
    "#print('Hyper-tuned model training mean :')\n",
    "#print(gb_train_mean)\n",
    "#print('Hyper-tuned model training std :')\n",
    "#print(gb_train_std)\n",
    "\n",
    "#print('Hyper-tuned model training mean for split1 :')\n",
    "#print(gb_train_mean_sp0)\n",
    "\n",
    "#print('Hyper-tuned model training mean for split2 :')\n",
    "#print(gb_train_mean_sp1)\n",
    "\n",
    "#print('Hyper-tuned model training mean for split3 :')\n",
    "#print(gb_train_mean_sp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(gb_cv_results[\"split1_train_score\"])\n",
    "#print(gb_cv_results[\"split1_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a XGBoost model\n",
    "#xgb = XGBClassifier(\n",
    "#                    learning_rate =0.01,\n",
    "#                    n_estimators=495,\n",
    "#                    booster = 'gblinear',\n",
    "#                    max_depth = 22,\n",
    "#                     min_child_weight=0,\n",
    "#                     subsample=0.85,\n",
    "#                     colsample_bytree=0.13,\n",
    "#                     objective= 'binary:logistic',\n",
    "#                    reg_lambda = 12,\n",
    "#                    reg_alpha =0,\n",
    "#                    random_state=42)\n",
    "# if using the randomSearch method\n",
    "#xgb = gb_estimator\n",
    "\n",
    "# if using GridSearch method\n",
    "xgb = gsearch3.best_estimator_\n",
    "\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "#xgb_scores = cross_val_score(xgb, X, y, cv = cv, scoring=multiclass_score)\n",
    "#xgb_pred = cross_val_predict(xgb, X, y, cv = 3)\n",
    "\n",
    "##!!!!\n",
    "#notice that mean of auroc of each fold is different from the auroc calculated by all the predicted probability\n",
    "#svm_scores = cross_val_score(svm_model_linear, X, y, cv = cv, scoring=multiclass_score)\n",
    "y_xgb_prob = cross_val_predict(xgb, X, y, cv = cv, method = 'predict_proba')\n",
    "\n",
    "# calculate the auroc by directly using the multiclass_roc_auc_score scorer\n",
    "#xgb_multiclass_auroc = multiclass_roc_auc_score(y, y_xgb_prob, average=\"weighted\")\n",
    "\n",
    "# calculate the auroc by directly using the binaryiclass_roc_auc_score scorer\n",
    "xgb_multiclass_auroc = binary_class_roc_auc_score(y, y_xgb_prob[:,1], average=\"weighted\")\n",
    "\n",
    "print(xgb)\n",
    "print(\"Auroc across all folds: %0.5f\" % (xgb_multiclass_auroc))\n",
    "\n",
    "#for train_index0, test_index0 in cv.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index0, \"TEST:\", test_index0)\n",
    "        \n",
    "#print(compress_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Predicted labels are:\")\n",
    "#print(xgb_pred)\n",
    "\n",
    "#output predicted labels\n",
    "#XGboost\n",
    "#xgb_pred_df = pd.DataFrame(xgb_pred)\n",
    "#xgb_pred_file = os.path.join(\"predicted_labels\", \"xgb_pred.tsv\")\n",
    "#xgb_pred_df.to_csv(xgb_pred_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed)\n",
    "y_xgb_pred = cross_val_predict(xgb, X, y, cv = cv)\n",
    "xgb_conf_mat = confusion_matrix(y,y_xgb_pred)\n",
    "\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#print(roc_auc_score(y, y_xgb_pred))\n",
    "\n",
    "print(xgb_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the importance of features, and see actually how many are useful\n",
    "np.count_nonzero(xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#plot feature importance\n",
    "###########################################\n",
    "import xgboost\n",
    "xgboost.plot_importance(xgb)\n",
    "plt.rcParams['figure.figsize'] = [10, 30]\n",
    "#plt.savefig('counts_data/(0806)Feature_Importance(deep10+3L_0.1t_0.2var)(BLCA,seed9).png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#print out binary class roc auc figure\n",
    "############################################\n",
    "fpr, tpr, threshold = metrics.roc_curve(y,y_xgb_prob[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#print out multiclass roc auc figure\n",
    "############################################\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed)\n",
    "y_xgb_prob = cross_val_predict(xgb, X, y, cv = cv, method = 'predict_proba')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10, 8))\n",
    "plot_multiclass_roc_auc(y, y_xgb_prob, n_classes = 3, title = \"xgb, SARC_high_var_0.2, 4 layers\")\n",
    "plt.savefig('(0606)3class_roc_auc_xgb(4layers12k_0.1test)(SARC_high_var_0.2).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#Generate confusion matrix figure and save those figures\n",
    "#Notice remember to change file name based on the input dataset\n",
    "###################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from matplotlib.pyplot import legend\n",
    "\n",
    "labels = ['Complete Response', 'Clinical Progressive Disease', 'Radiographic Progressive Disease', 'Stable Disease']\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "legend(labels)\n",
    "plot_confusion_matrix(xgb_conf_mat, classes=labels,\n",
    "                      title='Confusion matrix svm, without normalization')\n",
    "plt.savefig('(0414)Confusion_matrix_xgb(SARC0.1)(without_normalization).png')\n",
    "\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "legend(labels)\n",
    "plot_confusion_matrix(xgb_conf_mat, classes=labels, normalize = True,\n",
    "                      title='Normalized Confusion matrix svm')\n",
    "plt.savefig('(0414)Confusion_matrix_xgb(SARC0.1)(normalized).png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu-test]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
