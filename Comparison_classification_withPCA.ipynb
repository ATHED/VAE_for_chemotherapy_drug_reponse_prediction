{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "43acf223-9c88-4b10-bd83-39e96164929e"
    }
   },
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "4701a722-88f0-4de7-9d04-344a467a7a97"
    }
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "# import system level packages\n",
    "import sys\n",
    "#!{sys.executable} -m pip install numpy\n",
    "#!{sys.executable} -m pip install requests\n",
    "#import requests\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras import utils\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "#from .tqdm_callback import TQDMNotebookCallback\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#test tensorflow, remember to change the kernel\n",
    "#using kernel that supports GPU computing\n",
    "#simple test to confirm tensorflow is actually working\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(\"10 + 32 = \", sess.run(a + b))\n",
    "\n",
    "#manually set the random seed to define a replication\n",
    "r_seed = 55555\n",
    "\n",
    "#manually set the number for cross validation\n",
    "num_cv = 5\n",
    "\n",
    "print(\"current random seed is: \", r_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "#check the system information, check if cuda and gpu computing for tensorflow is installed properly\n",
    "print(\"whether tensorflow is built with cuda: \", tf.test.is_built_with_cuda())\n",
    "print(\"whether gpu computing is available for tensorflow: \", tf.test.is_gpu_available())\n",
    "print(\"using keras version: \", keras.__version__)\n",
    "print(\"using tensorflow version: \", tf.__version__)\n",
    "print(\"\\n\")\n",
    "print(\"Device details:\\n\", device_lib.list_local_devices())\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "60c01d38-f6b9-4c45-aab9-97901c1ad15f"
    }
   },
   "source": [
    "Load packages and use tensorflow as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "d5c264da-28ad-4827-a070-0f2f4071f514"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "import keras\n",
    "from keras import utils\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "#from .tqdm_callback import TQDMNotebookCallback\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c91bff03-2c49-4189-95ee-f8bdb5fb9660"
    }
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from scipy import interp\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#use all samples\n",
    "################\n",
    "#Reading files/documents\n",
    "compress_path = '/media/qiwei/work/Python_playground/VAE/TCGA_5_cancers/counts_data/high_var_counts_data/TCGA_(BLCA_COAD_SARC_PAAD_BRCA)_(0.2chemo)VSTnrom_count_expr_clinical_data.txt'\n",
    "\n",
    "#open(path).readline()\n",
    "#gene expression RNAseq, Batch effects normalized mRNA data\n",
    "\n",
    "og_data = pd.read_csv(compress_path, sep = \"\\t\", index_col = 0)\n",
    "og_data = og_data.dropna(axis='columns')\n",
    "\n",
    "og_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#og_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the features\n",
    "#df_stand = StandardScaler().fit_transform(og_data)\n",
    "#df_stand\n",
    "\n",
    "#Dont use standardizing\n",
    "#df_stand = og_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Projection using Minka's MLE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components = 'mle', svd_solver = 'full')\n",
    "\n",
    "#use this, if using all dimension\n",
    "#pca = PCA(n_components = None, svd_solver = 'auto')\n",
    "\n",
    "#use this, if selecting the amount of variance that needs to be explained is greater than the percentage specified by n_components.\n",
    "#pca = PCA(n_components = 0.9, svd_solver = 'full')\n",
    "\n",
    "#print(pca)\n",
    "#principalComponents = pca.fit_transform(df_stand)\n",
    "#principalDf = pd.DataFrame(data = principalComponents, index = og_data.index)\n",
    "#import csv\n",
    "#principalDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"pca_explained_var_ratio(all_5_cancers).csv\", pca.explained_variance_ratio_, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "#plt.figure()\n",
    "#plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "#plt.xlabel('Number of Components')\n",
    "#plt.ylabel('Variance (%)') #for each component\n",
    "#plt.title('Pancreatic Adenocarcinoma Dataset Explained Variance')\n",
    "#plt.savefig('5_cancers_PCA_Explained_Variance(thre_0.9).png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode rnaseq into the hidden/latent representation - and save output\n",
    "#encoded_rnaseq_df = pd.DataFrame(df_pca)\n",
    "\n",
    "#encoded_file = \"counts_data/pca_compressed/encoded_rnaseq_PAAD_pca(og,label,0.2_var,69sample).tsv\"\n",
    "#encoded_rnaseq_df.to_csv(encoded_file, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode rnaseq into the hidden/latent representation - and save output (all samples)\n",
    "#encoded_rnaseq_df = pd.DataFrame(principalDf)\n",
    "\n",
    "#encoded_file = \"counts_data/pca_compressed/encoded_rnaseq_5cancers_pca_0.9(og,unlabel,0.2_var,all_sample).tsv\"\n",
    "#encoded_rnaseq_df.to_csv(encoded_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#skip PCA part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip the PCA part\n",
    "\n",
    "#Reading files/documents\n",
    "#without grade\n",
    "pca_path = 'counts_data/pca_compressed/encoded_rnaseq_COAD_pca_0.9_wLabels(og,5cancers,unlabel,0.2_var,all_sample).txt'\n",
    "\n",
    "#with grade\n",
    "#pca_path = 'counts_data/pca_compressed/encoded_rnaseq_BRCA_pca_0.9_wLabels(og,unlabel,0.2_var,all_sample).txt'\n",
    "\n",
    "#open(path).readline()\n",
    "\n",
    "df_pca = pd.read_csv(pca_path, sep = \"\\t\", index_col = 0)\n",
    "df_pca.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ba0a9ae7-8b4a-442c-bddd-096c5c059178"
    }
   },
   "outputs": [],
   "source": [
    "df_count = df_pca.groupby('response_group')['Ensembl_ID'].nunique()\n",
    "print(df_count)\n",
    "#df_count.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "#store the raw data, and use ensembl id as index\n",
    "#\n",
    "df_raw = df_pca.iloc[:, 0:]\n",
    "df_raw = df_raw.set_index('Ensembl_ID')\n",
    "\n",
    "#notice the last column is the response_group\n",
    "#df_raw.shape\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################!#################################\n",
    "#here begins full data\n",
    "################################\n",
    "#full data, 4 labels analysis\n",
    "#Complete Response    21\n",
    "#Clinical Progressive Disease    10\n",
    "#Radiographic Progressive Disease     7\n",
    "#Stable Disease     7\n",
    "\n",
    "#features\n",
    "df_raw_coln = len(df_raw.columns)\n",
    "X = df_raw.iloc[:,0:(df_raw_coln-1)]\n",
    "X = X.values\n",
    "\n",
    "#label/target\n",
    "y = df_raw.loc[:, 'response_group']\n",
    "y = y.values\n",
    "\n",
    "#!!!!!!!\n",
    "#check to confirm the last column is not response group, only y contains response group information\n",
    "col = X.shape[1]\n",
    "print(X[:,(col-1)])\n",
    "\n",
    "#df_cancer.head(10)\n",
    "#df_normal.head(10)\n",
    "\n",
    "class_names = np.unique(y)\n",
    "print(\"unique labels from y: \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#importing necessary libraries for scikit-learn\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "#from sklearn.grid_search import GridSearchCV   #!!!the grid search package that has issue, dont use it\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#plot area under curve graph\n",
    "#input: actual, true labels/target without one hot encoding\n",
    "#       probs, predicted probabilities\n",
    "#       n_classes, number of unique classes in target\n",
    "#       title, input the title name for the figure\n",
    "#output: a roc curve plot for multi class task\n",
    "###############################################################\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_multiclass_roc_auc(actual, probs, n_classes, title = 'multi-class roc'):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(actual)\n",
    "    actual = lb.transform(actual)\n",
    "    y_prob = probs\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(actual[:, i], y_prob[:, i])\n",
    "        #please notice the difference between auc() and roc_auc_score()\n",
    "        #also auc() only works on monotonic increasing or monotonic\n",
    "        #decreasing input x\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        colors = cycle(['blue', 'red', 'green', 'orange'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color,\n",
    "        label='ROC curve of class {0} (area = {1:0.10f})'\n",
    "            ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for multi-class data using '+title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #commented thus being able to use fig save function\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#Random search CV method\n",
    "#and\n",
    "#Multi class roc_auc score method\n",
    "########################################################\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "###########################################################################################\n",
    "#Multi class roc_auc score method\n",
    "#input: y_test, true labels from test fold\n",
    "#       y_prob, predicted probability on test fold\n",
    "#       average, string, [None, ‘micro’, ‘macro’ (default), ‘samples’, ‘weighted’]\n",
    "#                'macro': Calculate metrics for each label, and find their unweighted mean. \n",
    "#                This does not take label imbalance into account.\n",
    "#                'weighted': Calculate metrics for each label, and find their average, \n",
    "#                weighted by support (the number of true instances for each label).\n",
    "#output: auroc value for each class\n",
    "#multiclass_score, an implemented scoring method for multi class task\n",
    "#!!!\n",
    "#Notice that by default,needs_proba : boolean, default=False\n",
    "#thus the multiclass_score will try to use the predicted label instead of predicted probability to calculate roc\n",
    "#which is not correct, and will causing the tuning process to not find the best parameters\n",
    "##############################################################################################\n",
    "def multiclass_roc_auc_score(y_test, y_prob, average=\"weighted\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    #y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_prob, average=average)\n",
    "\n",
    "#!!!\n",
    "#Notice that by default,needs_proba : boolean, default=False\n",
    "#thus the multiclass_score will try to use the predicted label instead of predicted probability to calculate roc\n",
    "#which is not correct, and will causing the tuning process to not find the best parameters\n",
    "multiclass_score = make_scorer(multiclass_roc_auc_score, needs_proba = True)\n",
    "\n",
    "###############################################################################################\n",
    "#Binary class roc auc score method\n",
    "#input: y_true, true labels from test fold\n",
    "#       y_score, predicted probability on test fold\n",
    "#       average, string, [None, ‘micro’, ‘macro’ (default), ‘samples’, ‘weighted’]\n",
    "#                'macro': Calculate metrics for each label, and find their unweighted mean. \n",
    "#                This does not take label imbalance into account.\n",
    "#                'weighted': Calculate metrics for each label, and find their average, \n",
    "#                weighted by support (the number of true instances for each label).\n",
    "#output: auroc value for each class\n",
    "#############################################################################################\n",
    "def binary_class_roc_auc_score(y_true, y_score, average=\"weighted\"):\n",
    "\n",
    "    return roc_auc_score(y_true, y_score, average=average)\n",
    "\n",
    "binaryclass_score = make_scorer(binary_class_roc_auc_score, needs_threshold = True)\n",
    "\n",
    "###################################################################################\n",
    "#Random search CV method\n",
    "#input: est, input estimator/classifier\n",
    "#       p_distr, the grid of parameters to search on\n",
    "#       nbr_iter, numbers of iteration on random search\n",
    "#       X, feature, y, true labels\n",
    "#output: ht_estimator, best estimator based on mean value of all folds\n",
    "#        ht_params, best parameters\n",
    "#\n",
    "################################################################################################\n",
    "def hypertuning_rscv(est, p_distr, nbr_iter,X,y):\n",
    "    #seed = 42\n",
    "    cv = StratifiedKFold(n_splits = 3, random_state = r_seed, shuffle = True)\n",
    "    rdmsearch = RandomizedSearchCV(est, param_distributions=p_distr, scoring=multiclass_score,\n",
    "                                  n_jobs=-1, n_iter=nbr_iter, cv=cv, return_train_score = True, verbose =10)\n",
    "    #CV = Cross-Validation ( here using Stratified KFold CV) #,random_state = seed\n",
    "    start = time()\n",
    "    rdmsearch.fit(X,y)\n",
    "    print('hyper-tuning time : %d seconds' % (time()-start))\n",
    "    start = 0\n",
    "   # ht_train_mean = rdmsearch.cv_results_['mean_train_score']\n",
    "   # ht_train_std = rdmsearch.cv_results_['std_train_score']\n",
    "   # ht_test_mean_sp0 = rdmsearch.cv_results_['split0_test_score']\n",
    "   # ht_test_mean_sp1 = rdmsearch.cv_results_['split1_test_score']\n",
    "   # ht_test_mean_sp2 = rdmsearch.cv_results_['split2_test_score']\n",
    "    #ht_train_mean_sp3 = rdmsearch.cv_results_['split3_train_score']\n",
    "    #ht_train_mean_sp4 = rdmsearch.cv_results_['split4_train_score']\n",
    "    #ht_best_loc = np.where(rdmsearch.cv_results_['rank_test_score'] == 1)\n",
    "    \n",
    "    ht_cv_results = rdmsearch.cv_results_\n",
    "    ht_estimator = rdmsearch.best_estimator_\n",
    "    ht_params = rdmsearch.best_params_\n",
    "    #ht_score = rdmsearch.best_score_\n",
    "    \n",
    "    return ht_estimator, ht_params, ht_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "be92a3df-606c-4a60-8ead-91bf99aac018"
    }
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#Grid search Tune learning rate, n_estimators, and booster\n",
    "#default is max_depth = 5, min_child_weight = 1\n",
    "###################################################\n",
    "param_test3 = {\n",
    " 'learning_rate':[0.05, 0.1, 0.2, 0.4, 0.6, 0.8],\n",
    " 'n_estimators':[i for i in range(1,40)],\n",
    " 'booster':['gbtree'],\n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(), \n",
    " param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Grid search Tune max_depth and min_child_weight\n",
    "#default\n",
    "#################################\n",
    "param_test3 = {\n",
    " 'max_depth':[i for i in range(1,10)],\n",
    " 'min_child_weight':[i for i in range(0,10)],\n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.6, n_estimators=10, booster = 'gbtree'), \n",
    " param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Grid search Tune subsample and colsample\n",
    "#\n",
    "#################################\n",
    "param_test3 = {\n",
    "             'subsample':[i/100.0 for i in range(10,110,10)],\n",
    "             'colsample_bytree':[i/100.0 for i in range(10,110,10)],\n",
    "             \n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.6, n_estimators=10, booster = 'gbtree',\n",
    "                                                 max_depth = 5, min_child_weight=0), \n",
    "  param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Grid search Tune subsample and colsample\n",
    "#\n",
    "#################################\n",
    "param_test3 = {\n",
    "             'reg_alpha':[i for i in range(0,3)],\n",
    "             'reg_lambda':[i for i in range(1,100)],\n",
    "    'silent':[True],\n",
    "    'random_state':[r_seed]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.6, n_estimators=10, booster = 'gbtree',\n",
    "                                                 max_depth = 5, min_child_weight=0, subsample = 1.0,\n",
    "                                                 colsample_bytree = 1.0), \n",
    "  param_grid = param_test3, scoring=\"roc_auc\",n_jobs=-1,iid=False, cv=cv,verbose=10)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a XGBoost model\n",
    "#xgb = XGBClassifier(\n",
    "#                    learning_rate =0.01,\n",
    "#                    n_estimators=495,\n",
    "#                    booster = 'gblinear',\n",
    "#                    max_depth = 22,\n",
    "#                     min_child_weight=0,\n",
    "#                     subsample=0.85,\n",
    "#                     colsample_bytree=0.13,\n",
    "#                     objective= 'binary:logistic',\n",
    "#                    reg_lambda = 12,\n",
    "#                    reg_alpha =0,\n",
    "#                    random_state=42)\n",
    "# if using the randomSearch method\n",
    "#xgb = gb_estimator\n",
    "\n",
    "# if using GridSearch method\n",
    "xgb = gsearch3.best_estimator_\n",
    "\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed, shuffle = True)\n",
    "\n",
    "#xgb_scores = cross_val_score(xgb, X, y, cv = cv, scoring=multiclass_score)\n",
    "#xgb_pred = cross_val_predict(xgb, X, y, cv = 3)\n",
    "\n",
    "##!!!!\n",
    "#notice that mean of auroc of each fold is different from the auroc calculated by all the predicted probability\n",
    "#svm_scores = cross_val_score(svm_model_linear, X, y, cv = cv, scoring=multiclass_score)\n",
    "y_xgb_prob = cross_val_predict(xgb, X, y, cv = cv, method = 'predict_proba')\n",
    "\n",
    "# calculate the auroc by directly using the multiclass_roc_auc_score scorer\n",
    "#xgb_multiclass_auroc = multiclass_roc_auc_score(y, y_xgb_prob, average=\"weighted\")\n",
    "\n",
    "# calculate the auroc by directly using the binaryiclass_roc_auc_score scorer\n",
    "xgb_multiclass_auroc = binary_class_roc_auc_score(y, y_xgb_prob[:,1], average=\"weighted\")\n",
    "\n",
    "print(xgb)\n",
    "print(\"Auroc across all folds: %0.5f\" % (xgb_multiclass_auroc))\n",
    "\n",
    "#for train_index0, test_index0 in cv.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index0, \"TEST:\", test_index0)\n",
    "        \n",
    "#print(compress_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cv = StratifiedKFold(n_splits = num_cv, random_state = r_seed)\n",
    "y_xgb_pred = cross_val_predict(xgb, X, y, cv = cv)\n",
    "xgb_conf_mat = confusion_matrix(y,y_xgb_pred)\n",
    "\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#print(roc_auc_score(y, y_xgb_pred))\n",
    "\n",
    "print(xgb_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.feature_importances_\n",
    "\n",
    "np.savetxt(\"feature_importance(seed?).csv\", xgb.feature_importances_, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the importance of features, and see actually how many are useful\n",
    "np.count_nonzero(xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#plot feature importance\n",
    "###########################################\n",
    "import xgboost\n",
    "xgboost.plot_importance(xgb)\n",
    "plt.rcParams['figure.figsize'] = [10, 30]\n",
    "#plt.savefig('counts_data/(0806)Feature_Importance(deep10+3L_0.1t_0.2var)(BLCA,seed9).png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#print out binary class roc auc figure\n",
    "############################################\n",
    "fpr, tpr, threshold = metrics.roc_curve(y,y_xgb_prob[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu-test]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
